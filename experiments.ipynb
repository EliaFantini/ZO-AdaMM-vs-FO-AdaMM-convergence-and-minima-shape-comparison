{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiments\n",
    "\n",
    "In this notebook, the different models are trained and the necessary data are recorded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from main import experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this section we proceed to train the scalable model for the different scales.\n",
    "\n",
    "We set the different parameters :\n",
    "- Batch size : 128\n",
    "- Scales ```torch.linspace(1.0/9, 120 - 1/9, 50)```, corresponding to 1'400 up to 2'806'751 parameters.\n",
    "- Initial learning rate : $10^{-3}$\n",
    "- $\\beta_1=0.9$ and $\\beta_2 = 0.999$, numerical stability variable $\\varepsilon = 10^{-8}$\n",
    "- 50 epochs\n",
    "- MNIST dataset\n",
    "- Use learning rate scheduler. It reduces by half the learning rate (and $\\mu$ if we are using the ZO method) if the validation loss did not improve over the last 2 epochs.\n",
    "- 10 experiments (i.e. 10 trainings of the same model) for each optimizer and each scale. The seed is incremented after each experiment.\n",
    "\n",
    "The models' architecture is as follows :\n",
    "1. convolution, followed by ReLU and max pooling\n",
    "2. convolution, followed by ReLU and max pooling\n",
    "3. fully connected layer, followed by ReLU\n",
    "4. fully connected layer, followed by ReLU\n",
    "5. fully connected layer\n",
    "\n",
    "The scaling is done on the fully connected layers only by increasing the number of neurons in each of the hidden fully connected layers.\n",
    "\n",
    "During the experiments, we record the learned weights of the models after each epoch.\n",
    "\n",
    "**Important note** : before running the experiments, you need to create the following folders :\n",
    "- ```./results```\n",
    "- ```./results/weights```\n",
    "\n",
    "Not doing so will result in an error when trying to save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration for ZO-AdaMM\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 128,\n",
    "    \"net\": \"scalable\",\n",
    "    \"scale\": 1.0/9,\n",
    "    \"opt_params\": [1e-3, 0.9, 0.999, 1e-8],\n",
    "    \"optimizer\": 'ZO-AdaMM',\n",
    "    \"epochs\": 50,\n",
    "    \"dataset\": \"mnist\",\n",
    "    \"zo_optim\": True,\n",
    "    \"mu\": 1e-3,\n",
    "    \"use_scheduler\": True,\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the different scales of the model\n",
    "scales = torch.linspace(1.0/9, 120 - 1/9, 50).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run the experiments for ZO-AdaMM\n",
    "experiments(config, 'results', scales, 10, record_weights=True, weights_path=f'results/weights/weights_sequence_zo_adamm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configuration for AdaMM\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"batch_size\": 128,\n",
    "    \"net\": \"scalable\",\n",
    "    \"scale\": 1.0/9,\n",
    "    \"opt_params\": [1e-3, 0.9, 0.999, 1e-8],\n",
    "    \"optimizer\": 'AdaMM',\n",
    "    \"epochs\": 50,\n",
    "    \"dataset\": \"mnist\",\n",
    "    \"zo_optim\": False,\n",
    "    \"mu\": 1e-3,\n",
    "    \"use_scheduler\": True,\n",
    "    \"verbose\": True\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run the experiments for AdaMM\n",
    "experiments(config, 'results', scales, 10, record_weights=True, weights_path=f'results/weights/weights_sequence_adamm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}